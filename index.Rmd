---
title: "COMPUTATIONAL MUSICOLOGY"
author: "Pierre Mugisha"
output: 
  flexdashboard::flex_dashboard:
    theme:
      version: 4
      bg: "#3000a1"
      fg: "#0058a1" 
      primary: "#2ad613"
      navbar-bg: "#3000a1"
      base_font: 
        google: Prompt
      heading_font:
        google: Sen
      code_font:
        google: 
          # arguments to sass::font_google() 
          family: JetBrains Mono
          local: false
    storyboard: true
    self_contained: false
    
---

```{r setup}
library(tidyverse)
library(plotly)
library(dplyr)
library(spotifyr)
library(compmus)
library(tidymodels)
library(ggdendro)
library(heatmaply)
```


### Introduction
  
```{r picture, echo = F, fig.cap = "newsroom.spotify.com", out.width = '100%'}
knitr::include_graphics("WHATS_NEW-HEADER-1440X733.png")

```


***
  
This storyboard is about my spotify wrapped playlist for 2021. For some features it is going to get compared to my spotify wrapped playlist of 2020.

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/37i9dQZF1EUMDoJuT8yJsl?utm_source=generator" width="100%" height="350" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>


***
As said above, the corpora used in this storyboard are my spotify wrapped playlist for 2020 and 2021. I've chosen these corpora,  because I listen to multiple different genres each year, and these playlists are a summarization of the year. The interesting part of these playlists is that it can show me my music listening behaviour during the pandemic/lockdown(from the start in 2020 up untill close to the end of it 2021)..

One of the natural "groups" in my corpus are the genres, I listen predominantly to the following genres: Hip Hop/Rap, House/Dance, Piano/Orchestra and sometimes Pop. I except some differences among these genres(e.g. tempo, speechiness, instrumentalness). Altough there is probably some overlap between the 2020 and the 2021 playlist, I also expect some differences between the playlist.

Some atypical tracks in my 2021 playlist are: "Un diavolo scaccia l'altro" of Lee Nyeom and "Retributor" of Lee Nyeom and Park Sejun. These tracks belong to the Original Television Soundtrack of VINCENZO -an K-action/drama show.

### DENDOGRAM

```{r}

get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}

halloween <-
  get_playlist_audio_features("", "6BKuhkNHlpwnhcRBR5GMlz?si=aa3d47a913f84195") %>%
  add_audio_analysis() %>%
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))

halloween <- halloween[1:50, ]                     # Extract first five rows

halloween_juice <-
  recipe(
    track.name ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = halloween
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>% 
  # step_range(all_predictors()) %>% 
  prep(halloween %>% mutate(track.name = str_trunc(track.name, 20))) %>%
  juice() %>%
  column_to_rownames("track.name")

halloween_dist <- dist(halloween_juice, method = "euclidean")

halloween_dist %>% 
  hclust(method = "average") %>% # Try single, average, and complete.
  dendro_data() %>%
  ggdendrogram()

```

***
The Dendogram on the left shows my top 50 songs clustered in different clusters. Using the average distance the result looks promising. For example, the dendogram clustered "Un diavolo scacci" and "Retributor" together, which have the same artists and both come from the same album. Further, I noticed that "Raw" and "Dansen Aan De Gracht" are also clustered together, which makes scence, because they are both Dutch Rap/Hip Hop songs. Moreover a lot of the Dutch songs seems to be clustered together. Perhaps that language is a strong discriminator!

### DR.Who?
```{r}
pata_pata <-
  get_tidy_audio_analysis("4yn7TG8nnispmUITZ7Bnd4?si=bd4092a7c0484e66") %>%
  select(segments) %>%
  unnest(segments)

pata_pata %>%
  mutate(loudness_max_time = start + loudness_max_time) %>%
  arrange(loudness_max_time) %>%
  mutate(delta_loudness = loudness_max - lag(loudness_max)) %>%
  ggplot(aes(x = loudness_max_time, y = pmax(0, delta_loudness))) +
  geom_line() +
  xlim(0, 100) +
  theme_minimal() +
  labs(x = "Time (s)", y = "Novelty")

pata_pata %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  arrange(start) %>%
  mutate(pitches = map2(pitches, lag(pitches), `-`)) %>%
  slice(-1) %>% 
  compmus_gather_chroma() %>% 
  group_by(start, duration) %>% 
  summarise(novelty = sum(log1p(pmax(value, 0)))) %>% 
  ggplot(aes(x = start + duration / 2, y = novelty)) +
  geom_line() +
  xlim(0, 100) +
  theme_minimal() +
  labs(x = "Time (s)", y = "Novelty")

```

***
One of my favorite club/dance song Dr.Who by [Tujamo](https://genius.com/artists/Tujamo) and [Plastic Funk](https://genius.com/artists/Plastik-funk)

*"Who" was first released as an instrumental in 2012. It became a hit at Winter Music Conference and was played by artists such as Avicii. In 2014, the song was rehashed as "Dr. Who!" and had vocals added to it by British rapper Sneakbo.These vocals namecheck Doctor Who, though do not directly pertain to the series.-wikipedia *

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/4yn7TG8nnispmUITZ7Bnd4?utm_source=generator" width="100%" height="380" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>

As can be seen by the figure on the left the energy starts out quiet normal and spikes up when the drop begins which after it drops down again and spikes up during the last drop

### Chordogram Analysis of a popular Intro
```{r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

intro <-
  get_tidy_audio_analysis("2usrT8QIbIk9y0NEtQwS4j?si=dde7b9ecff10417b") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

intro %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")

```

***
One of the most instrumental songs in my spotify wrapped 2021 playlist, Intro by [The XX](https://genius.com/artists/The-xx).

*“Intro”, a simple, two minute instrumental song is easily The xx’s most popular song. As of August 2017, it’s their most streamed song on Spotify. Notably, Rihanna sampled it for one of her songs, BBC used it as the soundtrack for their 2010 election coverage, and it was used in the coverage of many TV shows, including Law and Order.*
*In 2017, Spotify released a list of the top 10 songs most frequently appearing in user-created “Sex” playlists globally. Intro appeared on the list, making it — by the standards of Spotify users — one of the sexiest songs in the world. -Genius annotation*

The chordogram reflects the duration of the song clearly, because except from the part in the middle nd the end of the song nothing really changes beat-wise or key-wise. I think this is the reason why it is pleasant to listen to this song on repeat!

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/2usrT8QIbIk9y0NEtQwS4j?utm_source=generator" width="100%" height="380" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>

### Keys to my ear
```{r}
spot2020 <- get_playlist_audio_features("", "37i9dQZF1EMfweBkW6hPXV?si=540832d31503420a")
spot <- get_playlist_audio_features("", "6BKuhkNHlpwnhcRBR5GMlz?si=128d70c3b2624650")
top40_100 <- get_playlist_audio_features("", "1cCwREdWvFoeesP9B1we1v?si=7a4e539147da488a")
billboardhot100 <- get_playlist_audio_features("", "0ueT9dAlqLLaOxBuqQfN8Y?si=b9ba6f7ffd744eb9")

#####Selecting
spot2021 <- spot %>%
  select(danceability, energy, key, loudness, mode, speechiness,
         acousticness, instrumentalness, liveness, valence, tempo,
         track.duration_ms, track.explicit, track.name, track.popularity,
         track.album.release_date, track.album.artists)

spot2020_1 <- spot2020 %>%
  select(danceability, energy, key, loudness, mode, speechiness,
         acousticness, instrumentalness, liveness, valence, tempo,
         track.duration_ms, track.explicit, track.name, track.popularity,
         track.album.release_date, track.album.artists)

top40_2021 <- top40_100 %>%
  select(danceability, energy, key, loudness, mode, speechiness,
         acousticness, instrumentalness, liveness, valence, tempo,
         track.duration_ms, track.explicit, track.name, track.popularity,
         track.album.release_date, track.album.artists)

billboardhot100_2021 <- billboardhot100 %>%
  select(danceability, energy, key, loudness, mode, speechiness,
         acousticness, instrumentalness, liveness, valence, tempo,
         track.duration_ms, track.explicit, track.name, track.popularity,
         track.album.release_date, track.album.artists)


##Adding year
spot2021$newdate <- strptime(as.character(spot2021$track.album.release_date), "%Y-%m-%d")
spot2021$year <- format(spot2021$newdate, "%Y")

spot2021$newdate <- strptime(as.character(spot2021$track.album.release_date), "%Y")
spot2021$year <- format(spot2021$newdate, "%Y")

spot2020_1$newdate <- strptime(as.character(spot2020_1$track.album.release_date), "%Y-%m-%d")
spot2020_1$year <- format(spot2020_1$newdate, "%Y")

spot2020_1$newdate <- strptime(as.character(spot2020_1$track.album.release_date), "%Y")
spot2020_1$year <- format(spot2020_1$newdate, "%Y")

top40_2021$newdate <- strptime(as.character(top40_2021$track.album.release_date), "%Y-%m-%d")
top40_2021$year <- format(top40_2021$newdate, "%Y")

top40_2021$newdate <- strptime(as.character(top40_2021$track.album.release_date), "%Y")
top40_2021$year <- format(top40_2021$newdate, "%Y")

billboardhot100_2021$newdate <- strptime(as.character(billboardhot100_2021$track.album.release_date), "%Y-%m-%d")
billboardhot100_2021$year <- format(billboardhot100_2021$newdate, "%Y")

billboardhot100_2021$newdate <- strptime(as.character(billboardhot100_2021$track.album.release_date), "%Y")
billboardhot100_2021$year <- format(billboardhot100_2021$newdate, "%Y")


topnummers <-
  bind_rows(
    spot2020_1 %>% mutate(category = "Spotify Wrapped 2020"),
    spot2021 %>% mutate(category = "Spotify Wrapped 2021"),
    billboardhot100_2021 %>% mutate(category = "Billboard Hot 100: 2021"),
    top40_2021 %>% mutate(category = "Top40: Top 100 2021")
)

key_country <- topnummers%>%
  select(track.name, category, key)%>%
  group_by(category, key)%>%
  mutate(n=n())%>%
  unique()%>%
  group_by(key)%>%
  mutate(total=sum(n))%>%
  mutate(percent=round((n/total)*100))

green <- "#1ed760"
yellow <- "#e7e247"
pink <- "#ff6f59"
blue <- "#007be0"

viz3 <- ggplot(key_country, aes(x=key, fill=category, y = n, 
                                text = paste("Number of Songs: ", n, "<br>",
                                            "Percent Songs in Key: ", percent, "%")))+
  geom_bar(width=0.5, stat = "identity")+
  scale_fill_manual(values=c(green, yellow, pink, blue))+
  labs(x="Key", y="Number of Songs") +
  guides(fill=guide_legend(title="Playlist"))+
  theme_minimal()+
  ggtitle("Musical Key Makeup by Playlist")

ggplotly(viz3, tooltip=c("text"))

```
***
Musical key describes the scale on which a song is based. This means that most of the notes in a song will come from the scale of that key. In addition to my spotify wrapped 2020 -en 2021 playlists, the dutch top 100 of the top40 playlist and the Billboard top 100: 2021 are used for the key analysis.

***
The barplot on the left shows the percentage of songs in each key that come from each playlist(key distribution across playlists). According to the spotify API, the integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1.
It appears that I only have one song with the key-integer value of 3, in tonal, D-sharp/E-flat. The song in question is "Right Above It" by [Lil Wayne](https://genius.com/artists/Lil-wayne) and [Drake](https://genius.com/artists/Drake)

*“Right Above It” is Lil Wayne’s first single from his fresh-out-of-prison album, I’m Not A Human Being. It’s produced by the legendary Kane Beatz of “We Be Steady Mobbin” fame. As of 2015, the song is used as the opening theme to the HBO series Ballers. -Genius Annotation*

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/1kMuU3TNQvHbqvXCWBodmP?utm_source=generator" width="100%" height="380" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>

### Preliminary Visualisations
  
```{r}

spot2020 <- get_playlist_audio_features("", "37i9dQZF1EMfweBkW6hPXV?si=540832d31503420a")
spot <- get_playlist_audio_features("", "6BKuhkNHlpwnhcRBR5GMlz?si=128d70c3b2624650")

spot2021 <- spot %>%
  select(danceability, energy, key, loudness, mode, speechiness,
         acousticness, instrumentalness, liveness, valence, tempo,
         track.duration_ms, track.explicit, track.name, track.popularity,
         track.album.release_date, track.album.artists) #%>%
  #mutate(track.album.artists = str_c(track.album.artists, sep = " "))


spot2020_1 <- spot2020 %>%
  select(danceability, energy, key, loudness, mode, speechiness,
         acousticness, instrumentalness, liveness, valence, tempo,
         track.duration_ms, track.explicit, track.name, track.popularity,
         track.album.release_date, track.album.artists)

spot2021$newdate <- strptime(as.character(spot2021$track.album.release_date), "%Y-%m-%d")
spot2021$year <- format(spot2021$newdate, "%Y")

spot2021$newdate <- strptime(as.character(spot2021$track.album.release_date), "%Y")
spot2021$year <- format(spot2021$newdate, "%Y")

spot2020_1$newdate <- strptime(as.character(spot2020_1$track.album.release_date), "%Y-%m-%d")
spot2020_1$year <- format(spot2020_1$newdate, "%Y")

spot2020_1$newdate <- strptime(as.character(spot2020_1$track.album.release_date), "%Y")
spot2020_1$year <- format(spot2020_1$newdate, "%Y")

topnummers <-
  bind_rows(
    spot2020_1 %>% mutate(category = "2020"),
    spot2021 %>% mutate(category = "2021")
    
  )

topnummers_gg <- topnummers%>%                    # Start with awards.
  mutate(
    mode = ifelse(mode == 0, "Minor", "Major")
  ) %>%
  ggplot(                     # Set up the plot.
    aes(
      x = valence,
      y = energy,
      size = loudness,
      colour = mode,
      label = track.name
    )
  ) +
  geom_point() +              # Scatter plot.
  geom_rug(size = 0.1) +      # Add 'fringes' to show data distribution.
  geom_text(                  # Add text labels from above.
    aes(
      x = valence,
      y = energy,
      label = label
    ),
    data = 
      tibble(
        label = c("", ""),
        category = c("2020", "2021"),
        valence = c(0.090, 0.123),
        energy = c(0.101, 0.967)
      ),
    colour = "black",         # Override colour (not mode here).
    size = 3,                 # Override size (not loudness here).
    hjust = "left",           # Align left side of label with the point.
    vjust = "bottom",         # Align bottom of label with the point.
    nudge_x = -0.05,          # Nudge the label slightly left.
    nudge_y = 0.02            # Nudge the label slightly up.
  ) +
  facet_wrap(~category) +     # Separate charts per playlist.
  scale_x_continuous(         # Fine-tune the x axis.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),   # Use grid-lines for quadrants only.
    minor_breaks = NULL       # Remove 'minor' grid-lines.
  ) +
  scale_y_continuous(         # Fine-tune the y axis in the same way.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),
    minor_breaks = NULL
  ) +
  scale_colour_brewer(        # Use the Color Brewer to choose a palette.
    type = "qual",            # Qualitative set.
    palette = "Paired"        # Name of the palette is 'Paired'.
  ) +
  scale_size_continuous(      # Fine-tune the sizes of each point.
    trans = "exp",            # Use an exp transformation to emphasise loud.
    guide = "none"            # Remove the legend for size.
  ) +
  theme_light() +             # Use a simpler theme.
  labs(                       # Make the titles nice.
    x = "Valence",
    y = "Energy",
    colour = "Mode"
  )

ggplotly(topnummers_gg)



```


***
  
descr


### Chromagrams

```{r}
vinch1 <-
  get_tidy_audio_analysis("7AnHS1o08tFXLmnOedcucv?si=2bba8cb44ac6432f") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

vinch2 <-
  get_tidy_audio_analysis("1M4nbJUGkuBhI7Tx9lmeXp?si=e602daaa62524623") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

vinchenzo <-
  bind_rows(
    vinch1 %>% mutate(category = "Un diavolo scaccia l'altro"),
    vinch2 %>% mutate(category = "Retributor")
    
  )

vinchenzo %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  facet_wrap(~category) +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

```

***
Chromagram using euclidean

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/1M4nbJUGkuBhI7Tx9lmeXp?utm_source=generator" width="100%" height="80" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/7AnHS1o08tFXLmnOedcucv?utm_source=generator" width="100%" height="80" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>

###  Chroma -and Timbre Self-Similarity Matrices "Dark Horse" -Katy Perry, Juicy J
  
```{r}
vinchen1 <-
  get_tidy_audio_analysis("5jrdCoLpJSvHHorevXBATy?si=3bab498e69004e5a") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  vinchen1 %>% 
    compmus_self_similarity(pitches, "aitchison") %>% 
    mutate(d = d / max(d), type = "Chroma"),
  vinchen1 %>% 
    compmus_self_similarity(timbre, "euclidean") %>% 
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "C") +
  theme_classic() + 
  labs(x = "", y = "")
```

***
  
One song I liked to listen to in the gym in 2021 was 'Dark Horse'(2013) by [Katy Perry](https://genius.com/artists/Katy-perry) and [Juicy J](https://genius.com/artists/Juicy-j).

*Commercially, the song became Perry’s overall ninth number one single on the Billboard Hot 100, and her second from PRISM, as “Roar” reached the top spot months prior.*

due to the "Trap"-type beat and the verse of Juicy J. The chroma-based matrix of the song, picks up mostly the chorus of the song. In the timbre matrix, one can see the beginning of every verse and the end of the chorus(tiny square that gets faintly darker) clearly.

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/5jrdCoLpJSvHHorevXBATy?utm_source=generator" width="100%" height="380" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>

###  Chroma -and Timbre Self-Similarity Matrices "Power" -Kanye West
  
```{r}
difference <-
  get_tidy_audio_analysis("2gZUPNdnz5Y45eiGxpHGSc?si=4ad3b79c4ada47da") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  difference %>% 
    compmus_self_similarity(pitches, "aitchison") %>% 
    mutate(d = d / max(d), type = "Chroma"),
  difference %>% 
    compmus_self_similarity(timbre, "euclidean") %>% 
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(option = "C") +
  theme_classic() + 
  labs(x = "", y = "")
```

***

Another song I like to listen to in the gym is 'POWER' by *[Kanye West](https://genius.com/artists/Kanye-west)*.

*During an interview with New York radio station Power 105.1, West said he spent thousands of hours working on this carefully-crafted song. “A song like ‘Power’ took 5,000 hours, like literally 5,000 man-hours to do this one record. That’s the amount of time I was putting into every song on the album,” West revealed.*
*The accompanying music video has received critical acclaim. Russian supermodel Irina Shayk, who sits in a chair in the video, has called it “a moving painting”. -Genius Annotation*

This masterpiece, contains a lot of hidden messages in the lyrics and it contains vocals in the background almost throughout the whole song, this can be seen by the big square in the chroma matrix.

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/2gZUPNdnz5Y45eiGxpHGSc?utm_source=generator" width="100%" height="380" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>

Another part of the song that is picked up by the chroma matrix, is the part after the bridge. Here, right around 3:20 the track seems to slow down for a moment, and then it continues with the normal speed.
In the timbre matrix one can see the beginning and end of each verse.

###
```{r}

```

### Conclusion
```{r}

```




***
  
descr
